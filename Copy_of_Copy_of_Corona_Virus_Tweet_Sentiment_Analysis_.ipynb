{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhrisandamedhi/Corona-Virus-Tweet-Sentiment-/blob/main/Copy_of_Copy_of_Corona_Virus_Tweet_Sentiment_Analysis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Corona Virus Tweet Sentiment Analysis**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Classification\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##### **Contribution**    - Individual\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##### **Team Member 1 -** Dhrisanda Medhi\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words.\n",
        "\n",
        "COVID-19 originally known as Corona VIrus Disease of 2019, has been declared as a pandemic by World Health Organization (WHO) on 11th March 2020. Unprecedented pressures have mounted on each country to make compelling requisites for controlling the population by assessing the cases and properly utilizing available resources. The rapid number of exponential cases globally has become the apprehension of panic, fear and anxiety among people. The mental and physical health of the global population is found to be directly proportional to this pandemic disease. It is the need of the hour to implement different measures to safeguard the countries by demystifying the pertinent facts and information. I try to impement the covid sentimnet dataset and analysed the .sentiment accordingly. I used 4 algorithm to analysed this dataset.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here.\n",
        "\n",
        "https://github.com/dhrisandamedhi/Corona-Virus-Tweet-Sentiment-/blob/main/Copy_of_Corona_Virus_Tweet_Sentiment_Analysis_.ipynb"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "This challenge asks to build a classification model to predict the sentiment of COVID-19 tweets.\n",
        "The names and usernames have been given codes to avoid any privacy concerns.\n",
        "We are given the following information:\n",
        "\n",
        "1.Location\n",
        "\n",
        "2.Tweet At\n",
        "\n",
        "3.Original Tweet\n",
        "\n",
        "4.Sentiment"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "nltk.download('all',quiet=True)\n",
        "from PIL import Image\n",
        "\n",
        "#Model libraries\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries for text preprocessing and NLP\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "YKPhfPwQjSEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading data\n",
        "Tweet = pd.read_csv('/content/drive/MyDrive/Corona Virus Tweet Sentiment  analysis -Dhrisanda Medhi/Coronavirus Tweets.csv',encoding='latin-1')"
      ],
      "metadata": {
        "id": "XSmMO4TUeRQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "Tweet.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Last Look\n",
        "Tweet.tail()"
      ],
      "metadata": {
        "id": "e4Ei2-rVfIOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "Tweet.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "Tweet.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "Tweet.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "Tweet.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking  missing values in 'Location' column\n",
        "miss_value = Tweet['Location'].isnull().sum()/(Tweet.shape[0]) * 100\n",
        "print(\"We have {:.2f} % of missing values in 'Location' Column\".format(miss_value))"
      ],
      "metadata": {
        "id": "rlQThq66j4Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "import missingno as msno\n",
        "msno.bar(Tweet, figsize=(6,3), fontsize=8, color=\"darkblue\")"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here:\n",
        "\n",
        "In our dataset there are 6 columns and 411157 rows.\n",
        "\n",
        "In this dataset missing values are present in theloaction columns.No duplicate value is present here.\n",
        "\n",
        "\n",
        "User and Screenname   is int value and others are object type value."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "Tweet.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "Tweet.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "The original dataset has 6 columns and 41157 rows. In order to analyze various sentiments, We require just two columns named Original Tweet and Sentiment. There are five types of sentiments- Extremely Negative, Negative, Neutral, Positive, and Extremely Positive.\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "Tweet['UserName'].unique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet['ScreenName'].unique()"
      ],
      "metadata": {
        "id": "ITMJ7u_VoN45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet['Location'].unique()"
      ],
      "metadata": {
        "id": "M1fG2iXioUWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet['TweetAt'].unique()"
      ],
      "metadata": {
        "id": "mqxiQDWQoXXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet['OriginalTweet'].unique()"
      ],
      "metadata": {
        "id": "TU9h04SZoxx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet['Sentiment'].unique()"
      ],
      "metadata": {
        "id": "yLwakNUkoydz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code for changing format of date from object to datetime\n",
        "Tweet[\"TweetAt\"] = pd.to_datetime(Tweet[\"TweetAt\"])\n",
        "print(\"Minimum Invoice Date\", min(Tweet[\"TweetAt\"]))\n",
        "print(\"Maximum Invoice Date\", max(Tweet[\"TweetAt\"]))"
      ],
      "metadata": {
        "id": "AkC_BP3bpVn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extract day,month,year"
      ],
      "metadata": {
        "id": "R_bF6O0UwF7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Month extarct\n",
        "Tweet['Month'] = Tweet['TweetAt'].apply(lambda x: x.month)"
      ],
      "metadata": {
        "id": "M3A1Gx7zwHPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#date extract\n",
        "Tweet['Day'] = Tweet['TweetAt'].apply(lambda x: x.day)"
      ],
      "metadata": {
        "id": "QpKfBpsIwMAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#year extract\n",
        "Tweet['Year'] = Tweet['TweetAt'].apply(lambda x: x.year)"
      ],
      "metadata": {
        "id": "xADQo_38wO7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here. Extarct day,month and year from TweetAt columns so that we can find the maximum and minumum number day,month tweet."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Location"
      ],
      "metadata": {
        "id": "XuKDC5FOgdfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking the count value of different Location\n",
        "Tweet.Location.value_counts().head(15)"
      ],
      "metadata": {
        "id": "11BbKRKogiie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> Country london post most tweet and second is United state ."
      ],
      "metadata": {
        "id": "bHEu-q2Xsk-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking for the unique values in the variable\n",
        "Tweet.Location.unique()\n"
      ],
      "metadata": {
        "id": "aB4TKbuzhQ6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot No- 2\n",
        "# Looking for top 15 Countries in Countplot\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(y=Tweet.Location, order = Tweet.Location.value_counts().iloc[:15].index, palette ='icefire')\n",
        "plt.title('Top 15 locations')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3C683OBUh2jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above count plot shows the top 15 locations in the dataset.\n",
        "\n",
        "Plot shows the London to be the maximum among all the different locations.\n",
        "\n",
        "Second place is of United States and India ranks at 8th place."
      ],
      "metadata": {
        "id": "gwE0wNgKiDCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataframe for location\n",
        "location = pd.DataFrame(Tweet['Location'].value_counts().sort_values(ascending=False))\n",
        "location = location.rename(columns={'Location':'count'})"
      ],
      "metadata": {
        "id": "Zrr3jibfiPnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required library\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "EOnsPZEziVy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot No- 3\n",
        "# Plotting the interactive pie plot in percentage of Top 15 locations\n",
        "data = {\n",
        "   \"values\": location['count'][:15],\n",
        "   \"labels\": location.index[:15],\n",
        "   \"domain\": {\"column\": 0},\n",
        "   \"name\": \"Location Name\",\n",
        "   \"hoverinfo\":\"label+percent+name\",\n",
        "   \"hole\": .4,\n",
        "   \"type\": \"pie\"\n",
        "}\n",
        "layout = go.Layout(title=\"<b>Percentage of Location</b>\", legend=dict(x=0.1, y=1.0, orientation=\"v\"))\n",
        "data = [data]\n",
        "fig = go.Figure(data = data, layout = layout)\n",
        "fig.update_layout(title_x=0.5)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "A1pofIWTia5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can again see London has the maximum percentage share of 11.7%,\n",
        "\n",
        "followed by United States with 11.4% and again London, England with 11.2%.\n",
        "\n",
        "India which is placed at 8th place shares the percentage of 5.8%."
      ],
      "metadata": {
        "id": "sqZJC71eik4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #pie plot represent of user name\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# y=UserName.value_counts.head(10)\n",
        "\n",
        "# plt.pie(y)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "XQEgveXxtn2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "Tweet.UserName.value_counts().sort_values().head(10).plot(kind='bar')\n",
        "\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "Tweet.ScreenName.value_counts().sort_values().head(10).plot(kind='bar')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njtRa5futPYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet.head()"
      ],
      "metadata": {
        "id": "GQFcmEHDe1HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "->Here we can see the Month ,day and year which extract feom TweetAt columns."
      ],
      "metadata": {
        "id": "QOMYZcOOuEtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tweet Date"
      ],
      "metadata": {
        "id": "rNN1qS9-mHa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot No- 4\n",
        "# Distribution of Dates of Tweets\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='TweetAt', data=Tweet, palette ='Dark2')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"Tweeting Dates\")\n",
        "plt.ylabel(\"Count\", fontsize = 12)\n",
        "plt.xlabel(\"TweetAt\",fontsize = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NMiy22EgmSCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above count plot shows the overall distribution of different tweeting dates in the dataset. Starting from the mid-month of March 2020 to mid-month of April 2020.\n",
        "\n",
        "From the we can find out that the date 20-03-2020 has the maximum count value among all the other occuring dates.\n",
        "\n",
        "Least count value is for date 28-03-2020.\n",
        "The tweeting date ranges from 16-03-2020 to 14-04-2020, which is approx 30 days in total."
      ],
      "metadata": {
        "id": "on2N60_nmcyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "sales_in_month=Tweet['Month'].value_counts().reset_index().rename(columns={'index':'Month','Month':'Sales_count'})\n",
        "# Tweet count in different months.\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.barplot(x=sales_in_month['Month'],y=sales_in_month['Month'])\n",
        "plt.title('Tweet  count in different Months ')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "->march is the maximum tweet count month.second is April.\n",
        "\n",
        "->Least is Jan and Dec."
      ],
      "metadata": {
        "id": "CwcmR8I0uemc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "sales_in_Day=Tweet['Day'].value_counts().reset_index().rename(columns={'index':'Day','Day':'Tweet_count'})\n",
        "# Tweet count in different day.\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.barplot(x=sales_in_Day['Day'],y=sales_in_Day['Tweet_count'])\n",
        "plt.title('Tweet count in different inYear ')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "->Day 4 is maximum tweet post.\n",
        "\n",
        "->least is 28 date."
      ],
      "metadata": {
        "id": "gQWfMQUDv4po"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sentiment"
      ],
      "metadata": {
        "id": "WEvdT1xJmoNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking unique values in Sentiment\n",
        "Tweet.Sentiment.unique()"
      ],
      "metadata": {
        "id": "ZOhiZ3pcn_ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describing the sentiments\n",
        "Tweet.Sentiment.describe()"
      ],
      "metadata": {
        "id": "54RZkacJoSnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Chart 5"
      ],
      "metadata": {
        "id": "tfe0xHwqvviC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(15,7))\n",
        "sentiment_count = Tweet['Sentiment'].value_counts().reset_index().rename(columns={'index':'Sentiment','Sentiment':'Sentiment_count'})\n",
        "# top 5 countries where max sell happens.\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.barplot(x=sentiment_count['Sentiment'].tail(5),y=sentiment_count['Sentiment_count'].tail(5))\n",
        "plt.title('Sentiment ')"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of \"Positive\" sentiments are higher than all other sentiments\n",
        "\n",
        "The above plot is showing the count value of different sentiments present in the dataset.\n",
        "\n",
        "The most common occuring sentiment is positive, followed by negative, neutral, extremely positive and least is extremely negative."
      ],
      "metadata": {
        "id": "BZ9WSuSEzki8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Remove"
      ],
      "metadata": {
        "id": "GZ39TyqQGo-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert upper case to lower case\n",
        "Tweet[\"OriginalTweet\"] = Tweet[\"OriginalTweet\"].str.lower()\n",
        "Tweet['OriginalTweet']"
      ],
      "metadata": {
        "id": "NZ7CfgqaCFCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####OriginalTweet Length"
      ],
      "metadata": {
        "id": "WCrNHYzNtt8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot No - 17\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.grid()\n",
        "plt.hist(Tweet['OriginalTweet'].str.len(), color='red')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Tweet Length')\n",
        "plt.title('Length of Tweets', fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iw0Ha1Lwt0lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4. Text Preprocessing Steps"
      ],
      "metadata": {
        "id": "8Lgrh6c3uHjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Short Overview:\n",
        "\n",
        "The preprocessing of the text data is an essential step as it makes the raw text ready for mining.\n",
        "\n",
        "The objective of this step is to clean noise those are less relevant to find\n",
        "the sentiment of tweets such as punctuation, special characters, numbers, and terms which don’t carry much weightage in context to the text.\n",
        "\n",
        "As mentioned earlier, the tweets contain lots of twitter handles (@user). We will remove all these twitter handles from the data as they don’t convey much information.\n",
        "We are having twitter links in the data which are not useful for our Model. It will make our data noisy.\n",
        "As discussed, punctuations, numbers and special characters do not help much. It is better to remove them from the text just as we removed the twitter handles,links and hashtags.\n",
        "Stop words are those words in natural language that have a very little meaning, such as \"is\", \"an\", \"the\", etc.To remove stop words from a sentence, you can divide your text into words and then remove the word if it exits in the list of stop words provided by NLTK.\n",
        "Stemming is a rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “ed”, “s” etc) from a word. For example – “play”, “player”, “played”, “plays” and “playing” are the different variations of the word – “play”.\n",
        "In tokenization we convert group of sentence into token . It is also called text segmentation or lexical analysis. It is basically splitting data into small chunk of words. Tokenization in python can be done by python NLTK library’s word_tokenize() function."
      ],
      "metadata": {
        "id": "xUzoQjP6uokf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "sns.heatmap(Tweet[['ScreenName','Month','Day','TweetAt','UserName']].corr(),cmap=\"Reds\")\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(Tweet)\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "#Replace nan to 0\n",
        "Tweet=Tweet.fillna(0)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet.isna().sum()"
      ],
      "metadata": {
        "id": "O2eDcsBNv7ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "->All the missitng is replaced with 0.now there is no missing value."
      ],
      "metadata": {
        "id": "J-ffv7EDxMPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "Tweet.describe()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "->In our dataset no outlier present."
      ],
      "metadata": {
        "id": "zvWMFPSfxb9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Clean Data set"
      ],
      "metadata": {
        "id": "BT6rq2_x8gfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "df=Tweet[['OriginalTweet','Sentiment']]"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "tpCwWHYl2AVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "df[\"OriginalTweet\"] = df[\"OriginalTweet\"].str.lower()\n",
        "df['OriginalTweet']"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['OriginalTweet'] = df['OriginalTweet'].str.replace('http\\S+|www.\\S+', '', case=False)"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "wWQOEK5sF0-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def remove_punctuations(text):\n",
        "    for punctuation in string.punctuation:\n",
        "        text = text.replace(punctuation, '')\n",
        "    return text"
      ],
      "metadata": {
        "id": "2kiakhk8Fp7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"clean_tweets\"] = df['OriginalTweet'].apply(remove_punctuations)"
      ],
      "metadata": {
        "id": "Bf89EQBxGiQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_Zczcq0TGkmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "->store our clean Tweet in clean_tweets variable."
      ],
      "metadata": {
        "id": "FT3WAWA4x1sZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_tweets']"
      ],
      "metadata": {
        "id": "919I0rFiCRTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_tweets'] = df['clean_tweets'].str.replace(\"[^a-zA-Z#//]\",\" \")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "UK1myl_nCVv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_tweets'][0]"
      ],
      "metadata": {
        "id": "qnycOkhCCY5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can start our analyses using this clean tweet"
      ],
      "metadata": {
        "id": "2Yg97ZfQyE4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "#remove stopwords\n",
        "#function to remove stopwords and tokenize\n",
        "def remove_stopwords(text):\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "    return (text)"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_tweets']= df['clean_tweets'].apply(lambda x: remove_stopwords(x))"
      ],
      "metadata": {
        "id": "v2hWqFsdHcgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.clean_tweets[6]"
      ],
      "metadata": {
        "id": "l-P8p0-5Hjsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "fx8qvfGxKBH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "#stemming\n",
        "#function for stemming\n",
        "def stemming(text):\n",
        "    text = [stemmer.stem(word) for word in text]\n",
        "    return (\" \".join(text))\n",
        "df['stemmed'] = df['clean_tweets'].apply(lambda x: stemming(x))"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#result\n",
        "df.stemmed.head()"
      ],
      "metadata": {
        "id": "tryDaZ9sNHA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatizing"
      ],
      "metadata": {
        "id": "EhJCd5_0NplK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatizing\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "df['lemmed'] = df['clean_tweets'].apply(lambda x: [lemmatizer.lemmatize(y) for y in x])"
      ],
      "metadata": {
        "id": "ghS2GWVaNJXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "BbrrXEuSNlNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "Observation :\n",
        "\n",
        "**Stemmed**:\n",
        "\n",
        "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma.\n",
        "\n",
        "\n",
        "**Lemmed**:\n",
        "\n",
        "Lemmatization is the grouping together of different forms of the same word. In search queries, lemmatization allows end users to query any version of a base word and get relevant results."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train-Test Split"
      ],
      "metadata": {
        "id": "Z0snYh78Enys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning dependent and independent features\n",
        "X= df['lemmed']\n",
        "y=df['Sentiment']"
      ],
      "metadata": {
        "id": "3Z_rdJ8oEjCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Train test split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,stratify=y,random_state=10)"
      ],
      "metadata": {
        "id": "w5oLQgN2QxGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking shape of splitted data\n",
        "print(X_train.shape)\n",
        "y_test.shape"
      ],
      "metadata": {
        "id": "NWNTFh7dQ1nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking splitted data\n",
        "print(X_train.head())\n",
        "y_train.head()"
      ],
      "metadata": {
        "id": "ystfpgBrQ4Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "#Count Vectorization (Bag of words) and TF/IDF Vecorization\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of words\n",
        "cv=CountVectorizer(binary=False,max_df=1.0,min_df=5,ngram_range=(1,2))\n",
        "cv_X_train=cv.fit_transform(X_train.astype(str).str.strip())"
      ],
      "metadata": {
        "id": "cWuqLzyOEBa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "tv=TfidfVectorizer(use_idf=True,max_df=1.0,min_df=5,ngram_range=(1,2),sublinear_tf=True)\n",
        "tv_X_train=tv.fit_transform(X_train.astype(str).str.strip())"
      ],
      "metadata": {
        "id": "tn8PCceRRCVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv_X_train.shape"
      ],
      "metadata": {
        "id": "eHmzeOwQRIFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_X_test=cv.transform(X_test.astype(str).str.strip())\n",
        "tv_X_test=tv.transform(X_test.astype(str).str.strip())"
      ],
      "metadata": {
        "id": "neEDq6maRQLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Count Vectoriser Method with Gridsearch CV\n",
        "#Initalizing the model\n",
        "lr_cv = LogisticRegression()\n",
        "parameters = dict(penalty=['l1', 'l2'],C=[100, 10, 1.0, 0.1, 0.01])\n",
        "\n",
        "#Hyperparameter tuning by GridserchCV\n",
        "logreg_Gcv=GridSearchCV(lr_cv,parameters,cv=15)\n",
        "\n",
        "#fitting the data to model\n",
        "logreg_Gcv.fit(cv_X_train,y_train)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted values\n",
        "pred_lr_cv = logreg_Gcv.predict(cv_X_test)"
      ],
      "metadata": {
        "id": "K4KG9-YNsove"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr_cv"
      ],
      "metadata": {
        "id": "YcbaIJGQT_tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "accuracy_lr_cv = accuracy_score(y_test,pred_lr_cv)\n",
        "print(\"Accuracy :\",(accuracy_lr_cv))"
      ],
      "metadata": {
        "id": "EBrmHT4nUDVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Classification report of Performance metrics\n",
        "label=['neutral','positive','negative']\n",
        "print(classification_report(y_test,pred_lr_cv))"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Plotting Confussion matrix\n",
        "#Plotting Confussion matrix\n",
        "cf1= (confusion_matrix(y_test,pred_lr_cv))\n",
        "plt.figure(figsize=(8,5))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cf1, annot=True, fmt=\".0f\",ax = ax)\n",
        "\n",
        "# # labels, title and ticks\n",
        "# ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "# ax.set_ylabel('Actual labels', fontsize=15)\n",
        "# ax.set_title('Confusion Matrix (Logistic Regression with CV)', fontsize=20)\n",
        "# ax.xaxis.set_ticklabels(label)\n",
        "# ax.yaxis.set_ticklabels(label)"
      ],
      "metadata": {
        "id": "0jmM9lCAWlQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation :\n",
        "This model gives an accuracy score of 58% which implies that our model is performing well."
      ],
      "metadata": {
        "id": "d-nClX0mXbIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Decision Tree Classifier with CV"
      ],
      "metadata": {
        "id": "NH2i76YWYf7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing model\n",
        "dt_cv=DecisionTreeClassifier()\n",
        "\n",
        "#fitting the data to model\n",
        "dt_cv.fit(cv_X_train,y_train)\n",
        "\n",
        "#predicted values\n",
        "pred_dt_cv=dt_cv.predict(cv_X_test)"
      ],
      "metadata": {
        "id": "ZkA8hT9QYXcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dt_cv"
      ],
      "metadata": {
        "id": "aY-8v15iYkJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "cv_score_dt_cv= cross_val_score(dt_cv,cv_X_train,y_train, cv=5)\n",
        "print(\"Accuracy: {}\" .format(np.mean(cv_score_dt_cv)))"
      ],
      "metadata": {
        "id": "rFMlJklwYm04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,pred_dt_cv))"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Plotting Confussion matrix\n",
        "cf2= (confusion_matrix(y_test,pred_dt_cv))\n",
        "plt.figure(figsize=(8,5))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cf2, annot=True, fmt=\".0f\",ax = ax)\n",
        "\n",
        "# # labels, title and ticks\n",
        "# ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "# ax.set_ylabel('Actual labels', fontsize=15)\n",
        "# ax.set_title('Confusion Matrix (Decision tree with CV)', fontsize=20)\n",
        "# ax.xaxis.set_ticklabels(labels)\n",
        "# ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "L13HdD21ZMNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "Observation :\n",
        "\n",
        "This model gives an accuracy score of 49.04% which implies that our model is performing well."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###KNN"
      ],
      "metadata": {
        "id": "cLn0VXf-xuU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "# Initializing model\n",
        "knn = KNeighborsClassifier()\n",
        "param = {'n_neighbors': [1,2,3,4,5,6,7,8]}\n",
        "knn_cv = GridSearchCV(estimator=knn,param_grid=param)\n",
        "\n",
        "#fitting the data to model\n",
        "knn_cv.fit(cv_X_train, y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted values\n",
        "pred_knn_cv = knn_cv.predict(cv_X_test)"
      ],
      "metadata": {
        "id": "CfvYvqxXavWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_knn_cv"
      ],
      "metadata": {
        "id": "aZc5zNAzayT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy_KNN = accuracy_score(y_test,pred_knn_cv)\n",
        "print(\"Accuracy :\",(accuracy_KNN))"
      ],
      "metadata": {
        "id": "18ohgif6a0wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        " #Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,pred_knn_cv))"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Plotting Confussion matrix\n",
        "cf4= (confusion_matrix(y_test,pred_knn_cv))\n",
        "plt.figure(figsize=(8,5))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cf4, annot=True, fmt=\".0f\",ax = ax)\n",
        "\n",
        "# # labels, title and ticks\n",
        "# ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "# ax.set_ylabel('Actual labels', fontsize=15)\n",
        "# ax.set_title('Confusion Matrix (KNN with CV)', fontsize=20)\n",
        "# ax.xaxis.set_ticklabels(x_label)\n",
        "# ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "FOHsaMS0bJle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.Observation :\n",
        "\n",
        "The model is giving an accuracy score of 30% which implies that our model is underperforming."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. SVM with CV"
      ],
      "metadata": {
        "id": "onJO00ghckD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing model\n",
        "svm_cv = SVC()\n",
        "\n",
        "#fitting the data to model\n",
        "svm_cv.fit(cv_X_train,y_train)\n",
        "\n",
        "#prediction\n",
        "pred_svm_cv = svm_cv.predict(cv_X_test)"
      ],
      "metadata": {
        "id": "8ZIVi6_RcdaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_svm_cv"
      ],
      "metadata": {
        "id": "Dfq2kmF1ctnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy_svc = accuracy_score(y_test,pred_svm_cv)\n",
        "print(\"Accuracy :\",(accuracy_svc))"
      ],
      "metadata": {
        "id": "gB-s7QevcxO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,pred_svm_cv))"
      ],
      "metadata": {
        "id": "Fjhm0_yJcz_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Plotting Confussion matrix\n",
        "cf5= (confusion_matrix(y_test,pred_svm_cv))\n",
        "plt.figure(figsize=(8,5))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cf5, annot=True, fmt=\".0f\",ax = ax)\n",
        "\n",
        "# # labels, title and ticks\n",
        "# ax.set_xlabel('Predicted labels', fontsize=15)\n",
        "# ax.set_ylabel('Actual labels', fontsize=15)\n",
        "# ax.set_title('Confusion Matrix (SVM with CV)', fontsize=20)\n",
        "# ax.xaxis.set_ticklabels(labels)\n",
        "# ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "5p3Tb9URc37R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation :\n",
        "This model gives an accuracy score of 58% which implies that our model is performing well.\n",
        "\n"
      ],
      "metadata": {
        "id": "_IBnkCf1dFQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10. SVM with TF/ID"
      ],
      "metadata": {
        "id": "1Cx09TktdY--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing model\n",
        "svm_tv = SVC()\n",
        "\n",
        "#fitting the data to model\n",
        "svm_tv.fit(tv_X_train,y_train)\n",
        "\n",
        "#prediction\n",
        "pred_svm_tv = svm_tv.predict(tv_X_test)"
      ],
      "metadata": {
        "id": "-4s-h0r_dX24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_svm_tv"
      ],
      "metadata": {
        "id": "ge5l-SQadiZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy_svm_tv = accuracy_score(y_test,pred_svm_tv)\n",
        "print(\"Accuracy :\",(accuracy_svm_tv))"
      ],
      "metadata": {
        "id": "9jVH6g8Fdnmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report of Performance metrics\n",
        "label=['Neutral','Positive','Negative']\n",
        "print(classification_report(y_test,pred_svm_tv))"
      ],
      "metadata": {
        "id": "RvBE8hHgdsY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Plotting Confussion matrix\n",
        "cf5a= (confusion_matrix(y_test,pred_svm_tv))\n",
        "plt.figure(figsize=(8,5))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cf5a, annot=True, fmt=\".0f\",ax = ax)\n",
        "\n"
      ],
      "metadata": {
        "id": "ebLL8JqZdw6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation :\n",
        "This model gives an accuracy score of 57% which implies that our model is performing well."
      ],
      "metadata": {
        "id": "lz1Kr2l4d2jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model's acurracy Score Comparision\n",
        "\n",
        "# Model's acurracy Score Comparision\n",
        "\n",
        "acurracy = {'Model':  ['Logistic Regression with GridserachCV', 'Decision Tree Classifier','K-Nearest-Neighbours Classifier','Support-Vector-Machine Classifier'],\n",
        "        'Count Vector':  [accuracy_lr_cv,np.mean(cv_score_dt_cv),accuracy_KNN,accuracy_svc],\n",
        "        'Tf/idf Vector': [accuracy_lr_cv ,accuracy_KNN,accuracy_svm_tv,accuracy_svc]}\n",
        "\n",
        "cv_score_table= pd.DataFrame (acurracy, columns = ['Model','Count Vector','Tf/idf Vector'])\n",
        "\n",
        "cv_score_table"
      ],
      "metadata": {
        "id": "WBt6SLLTekuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here.\n",
        "\n",
        "Conclusions:\n",
        "1. We applied different machine learing models namely, Logistic Regression with Grid Search CV, Desision Tree Classifier, KNN, SVM Classifier for both Count Vector And TF IDF Vectorisation techniques.\n",
        "2. We conclude that the machine is generating best results for Logistic Regression with Grid Search CV model with and Accuracy score of 58.23% and 58.23.\n",
        "3. Also, we observed that no overfitting is seen for the data, and we can\n",
        "deploy this model.\n",
        "4. The sentiments of future tweets can be easily predicted using this model."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}